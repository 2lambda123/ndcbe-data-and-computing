{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vwvvdc673Awp"
   },
   "source": [
    "# Newton Methods in Scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "After studying this notebook, completing the activities, and asking questions in class, you should be able to:\n",
    "* Use numpy to solve the flash example problem from the [previous notebook](../04-publish/05-System-of-Equations-Newton-Method.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import numpy as np\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8HrL39kh_LnS",
    "tags": []
   },
   "source": [
    "## Using ``scipy`` instead\n",
    "\n",
    "`numpy` and `scipy` offer a few different implementations of Newton's method. However, we found these to be unreliable in the past. Instead, we recommend either using the Newton solver we put together in the [last notebook](../04-publish/05-System-of-Equations-Newton-Method.ipynb) or Pyomo (future notebook).\n",
    "\n",
    "However, we will show how this is done using `scipy.optimize.newton` in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function newton in module scipy.optimize._zeros_py:\n",
      "\n",
      "newton(func, x0, fprime=None, args=(), tol=1.48e-08, maxiter=50, fprime2=None, x1=None, rtol=0.0, full_output=False, disp=True)\n",
      "    Find a zero of a real or complex function using the Newton-Raphson\n",
      "    (or secant or Halley's) method.\n",
      "    \n",
      "    Find a zero of the scalar-valued function `func` given a nearby scalar\n",
      "    starting point `x0`.\n",
      "    The Newton-Raphson method is used if the derivative `fprime` of `func`\n",
      "    is provided, otherwise the secant method is used. If the second order\n",
      "    derivative `fprime2` of `func` is also provided, then Halley's method is\n",
      "    used.\n",
      "    \n",
      "    If `x0` is a sequence with more than one item, `newton` returns an array:\n",
      "    the zeros of the function from each (scalar) starting point in `x0`.\n",
      "    In this case, `func` must be vectorized to return a sequence or array of\n",
      "    the same shape as its first argument. If `fprime` (`fprime2`) is given,\n",
      "    then its return must also have the same shape: each element is the first\n",
      "    (second) derivative of `func` with respect to its only variable evaluated\n",
      "    at each element of its first argument.\n",
      "    \n",
      "    `newton` is for finding roots of a scalar-valued functions of a single\n",
      "    variable. For problems involving several variables, see `root`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    func : callable\n",
      "        The function whose zero is wanted. It must be a function of a\n",
      "        single variable of the form ``f(x,a,b,c...)``, where ``a,b,c...``\n",
      "        are extra arguments that can be passed in the `args` parameter.\n",
      "    x0 : float, sequence, or ndarray\n",
      "        An initial estimate of the zero that should be somewhere near the\n",
      "        actual zero. If not scalar, then `func` must be vectorized and return\n",
      "        a sequence or array of the same shape as its first argument.\n",
      "    fprime : callable, optional\n",
      "        The derivative of the function when available and convenient. If it\n",
      "        is None (default), then the secant method is used.\n",
      "    args : tuple, optional\n",
      "        Extra arguments to be used in the function call.\n",
      "    tol : float, optional\n",
      "        The allowable error of the zero value. If `func` is complex-valued,\n",
      "        a larger `tol` is recommended as both the real and imaginary parts\n",
      "        of `x` contribute to ``|x - x0|``.\n",
      "    maxiter : int, optional\n",
      "        Maximum number of iterations.\n",
      "    fprime2 : callable, optional\n",
      "        The second order derivative of the function when available and\n",
      "        convenient. If it is None (default), then the normal Newton-Raphson\n",
      "        or the secant method is used. If it is not None, then Halley's method\n",
      "        is used.\n",
      "    x1 : float, optional\n",
      "        Another estimate of the zero that should be somewhere near the\n",
      "        actual zero. Used if `fprime` is not provided.\n",
      "    rtol : float, optional\n",
      "        Tolerance (relative) for termination.\n",
      "    full_output : bool, optional\n",
      "        If `full_output` is False (default), the root is returned.\n",
      "        If True and `x0` is scalar, the return value is ``(x, r)``, where ``x``\n",
      "        is the root and ``r`` is a `RootResults` object.\n",
      "        If True and `x0` is non-scalar, the return value is ``(x, converged,\n",
      "        zero_der)`` (see Returns section for details).\n",
      "    disp : bool, optional\n",
      "        If True, raise a RuntimeError if the algorithm didn't converge, with\n",
      "        the error message containing the number of iterations and current\n",
      "        function value. Otherwise, the convergence status is recorded in a\n",
      "        `RootResults` return object.\n",
      "        Ignored if `x0` is not scalar.\n",
      "        *Note: this has little to do with displaying, however,\n",
      "        the `disp` keyword cannot be renamed for backwards compatibility.*\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    root : float, sequence, or ndarray\n",
      "        Estimated location where function is zero.\n",
      "    r : `RootResults`, optional\n",
      "        Present if ``full_output=True`` and `x0` is scalar.\n",
      "        Object containing information about the convergence. In particular,\n",
      "        ``r.converged`` is True if the routine converged.\n",
      "    converged : ndarray of bool, optional\n",
      "        Present if ``full_output=True`` and `x0` is non-scalar.\n",
      "        For vector functions, indicates which elements converged successfully.\n",
      "    zero_der : ndarray of bool, optional\n",
      "        Present if ``full_output=True`` and `x0` is non-scalar.\n",
      "        For vector functions, indicates which elements had a zero derivative.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    root_scalar : interface to root solvers for scalar functions\n",
      "    root : interface to root solvers for multi-input, multi-output functions\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The convergence rate of the Newton-Raphson method is quadratic,\n",
      "    the Halley method is cubic, and the secant method is\n",
      "    sub-quadratic. This means that if the function is well-behaved\n",
      "    the actual error in the estimated zero after the nth iteration\n",
      "    is approximately the square (cube for Halley) of the error\n",
      "    after the (n-1)th step. However, the stopping criterion used\n",
      "    here is the step size and there is no guarantee that a zero\n",
      "    has been found. Consequently, the result should be verified.\n",
      "    Safer algorithms are brentq, brenth, ridder, and bisect,\n",
      "    but they all require that the root first be bracketed in an\n",
      "    interval where the function changes sign. The brentq algorithm\n",
      "    is recommended for general use in one dimensional problems\n",
      "    when such an interval has been found.\n",
      "    \n",
      "    When `newton` is used with arrays, it is best suited for the following\n",
      "    types of problems:\n",
      "    \n",
      "    * The initial guesses, `x0`, are all relatively the same distance from\n",
      "      the roots.\n",
      "    * Some or all of the extra arguments, `args`, are also arrays so that a\n",
      "      class of similar problems can be solved together.\n",
      "    * The size of the initial guesses, `x0`, is larger than O(100) elements.\n",
      "      Otherwise, a naive loop may perform as well or better than a vector.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from scipy import optimize\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    \n",
      "    >>> def f(x):\n",
      "    ...     return (x**3 - 1)  # only one real root at x = 1\n",
      "    \n",
      "    ``fprime`` is not provided, use the secant method:\n",
      "    \n",
      "    >>> root = optimize.newton(f, 1.5)\n",
      "    >>> root\n",
      "    1.0000000000000016\n",
      "    >>> root = optimize.newton(f, 1.5, fprime2=lambda x: 6 * x)\n",
      "    >>> root\n",
      "    1.0000000000000016\n",
      "    \n",
      "    Only ``fprime`` is provided, use the Newton-Raphson method:\n",
      "    \n",
      "    >>> root = optimize.newton(f, 1.5, fprime=lambda x: 3 * x**2)\n",
      "    >>> root\n",
      "    1.0\n",
      "    \n",
      "    Both ``fprime2`` and ``fprime`` are provided, use Halley's method:\n",
      "    \n",
      "    >>> root = optimize.newton(f, 1.5, fprime=lambda x: 3 * x**2,\n",
      "    ...                        fprime2=lambda x: 6 * x)\n",
      "    >>> root\n",
      "    1.0\n",
      "    \n",
      "    When we want to find zeros for a set of related starting values and/or\n",
      "    function parameters, we can provide both of those as an array of inputs:\n",
      "    \n",
      "    >>> f = lambda x, a: x**3 - a\n",
      "    >>> fder = lambda x, a: 3 * x**2\n",
      "    >>> rng = np.random.default_rng()\n",
      "    >>> x = rng.standard_normal(100)\n",
      "    >>> a = np.arange(-50, 50)\n",
      "    >>> vec_res = optimize.newton(f, x, fprime=fder, args=(a, ), maxiter=200)\n",
      "    \n",
      "    The above is the equivalent of solving for each value in ``(x, a)``\n",
      "    separately in a for-loop, just faster:\n",
      "    \n",
      "    >>> loop_res = [optimize.newton(f, x0, fprime=fder, args=(a0,),\n",
      "    ...                             maxiter=200)\n",
      "    ...             for x0, a0 in zip(x, a)]\n",
      "    >>> np.allclose(vec_res, loop_res)\n",
      "    True\n",
      "    \n",
      "    Plot the results found for all values of ``a``:\n",
      "    \n",
      "    >>> analytical_result = np.sign(a) * np.abs(a)**(1/3)\n",
      "    >>> fig, ax = plt.subplots()\n",
      "    >>> ax.plot(a, analytical_result, 'o')\n",
      "    >>> ax.plot(a, vec_res, '.')\n",
      "    >>> ax.set_xlabel('$a$')\n",
      "    >>> ax.set_ylabel('$x$ where $f(x, a)=0$')\n",
      "    >>> plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# documentation for Newton's method in scipy\n",
    "help(optimize.newton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Polynomial Example Revisited Using Scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ c(x) = 3 x^3 + 2 x^2 - 5 x - 20 $$\n",
    "\n",
    "![Newton Polynomial](../../media/newton_polynomial.png)\n",
    "    \n",
    "In the following cells we will demonstrate the use of Scipy to perform the Newton-Raphson method for the polynomial example from [this previous notebook](../04-publish/02-Newton-Raphson-Method-in-One-Dimension.ipynb).\n",
    "\n",
    "First, we need to run the code we already developed for the polynomial function and its derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonlinear_function(x):\n",
    "    ''' compute a nonlinear function for demonstration\n",
    "    Arguments:\n",
    "        x: scalar\n",
    "    Returns:\n",
    "        c(x): scalar\n",
    "    '''\n",
    "    return 3*x**3 + 2*x**2 - 5*x-20\n",
    "\n",
    "def Dnonlinear_function(x):\n",
    "    ''' compute 1st derivative of nonlinear function for demonstration\n",
    "    Arguments:\n",
    "        x: scalar\n",
    "    Returns:\n",
    "        c'(x): scalar\n",
    "    '''\n",
    "    return 9*x**2 + 4*x - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to provide an initial guess as we did before we the code we deveoped for Newton's Method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run Newton's Method through `scipy.optimize.newton`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root is found at 1.9473052357731322\n"
     ]
    }
   ],
   "source": [
    "polysln = optimize.newton(func=nonlinear_function, x0 = guess, fprime=Dnonlinear_function)\n",
    "print(\"The root is found at\",polysln)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7nE5fTM23Ax_"
   },
   "source": [
    "## Flash Problem Revisted Using Scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yNNP7IN_3Ax_"
   },
   "source": [
    "Recall the flash problem from [this previous notebook](../04-publish/01-Modeling-Systems-of-Nonlinear-Equations.ipynb) that we solved in the [last notebook](../04-publish/05-Newton-Raphson-Methods-for-Systems-of-Equations.ipynb) using Newton's Method.  In the following cells we will demonstrate the use of Scipy to perform the Newton-Raphson method.\n",
    "\n",
    "![flash](../../media/flash-system.png)\n",
    "\n",
    "**Parameters (given)**:\n",
    "* $F$ feed inlet flowrate, mol/time or kg/time\n",
    "* $z_1$ composition of species 1 in feed, mol% or mass%\n",
    "* $z_2$ composition of species 2 in feed, mol% or mass%\n",
    "* $K_1$ partion coefficient for species 1, mol%/mol% or mass% / mass%\n",
    "* $K_2$ partion coefficient for species 2, mol%/mol% or mass% / mass%\n",
    "\n",
    "**Variables (unknown)**:\n",
    "* $L$ liquid outlet flowrate, mol/time or kg/time\n",
    "* $x_1$ composition of species 1 in liquid, mol% or mass%\n",
    "* $x_2$ composition of species 2 in liquid, mol% or mass%\n",
    "* $V$ vapor outlet flowrate, mol/time or kg/time\n",
    "* $y_1$ composition of species 1 in vapor, mol% or mass%\n",
    "* $y_2$ composition of species 2 in vapor, mol% or mass%\n",
    "\n",
    "How to solve the flash problem and other multidimensional problem with $n$ unknown variables and $n$ nonlinear equations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ejJp4YwW3AyF"
   },
   "source": [
    "### System of Equations in Canonical Form\n",
    "\n",
    "$$\\mathbf{F}(\\mathbf{x}) = \\begin{pmatrix}\n",
    "L + V - F\\\\\n",
    "Vy_1 + L x_1 - F z_1 \\\\\n",
    "V y_2 + L x_2 - F z_2 \\\\\n",
    "y_1 - K_1 x_1 \\\\\n",
    "y_2 - K_2 x_2 \\\\\n",
    "y_1 + y_2 - x_1 - x_2\n",
    "\\end{pmatrix},$$\n",
    "\n",
    "with $\\mathbf{x} = (L, V, x_1, x_2, y_1, y_2).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First run the code below to define the system of nonlinear equations given in the [previous notebook](../04-publish/05-Newton-Raphson-Methods-for-Systems-of-Equations.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Fv_aYYF3AyG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nonlinear canonical system of equations\n",
    "def my_f(x,verbose=False):\n",
    "    ''' Nonlinear system of equations in conancial form F(x) = 0\n",
    "    Copied from previous notebook.\n",
    "    \n",
    "    Arg:\n",
    "        x: vector of variables\n",
    "        \n",
    "    Returns:\n",
    "        r: residual, F(x)\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Initialize residuals\n",
    "    r = np.zeros(6)\n",
    "    \n",
    "    # given data\n",
    "    F = 1.0\n",
    "    z1 = 0.5\n",
    "    z2 = 0.5\n",
    "    K1 = 3\n",
    "    K2 = 0.05\n",
    "    \n",
    "    # copy values from x to more meaningful names\n",
    "    L = x[0]\n",
    "    V = x[1]\n",
    "    x1 = x[2]\n",
    "    x2 = x[3]\n",
    "    y1 = x[4]\n",
    "    y2 = x[5]\n",
    "    \n",
    "    # equation 1: overall mass balance\n",
    "    r[0] = V + L - F\n",
    "    \n",
    "    # equations 2 and 3: component mass balances\n",
    "    r[1] = V*y1 + L*x1 - F*z1\n",
    "    r[2] = V*y2 + L*x2 - F*z2\n",
    "    \n",
    "    # equation 4 and 5: equilibrium\n",
    "    r[3] = y1 - K1*x1\n",
    "    r[4] = y2 - K2*x2\n",
    "    \n",
    "    # equation 6: summation\n",
    "    r[5] = (y1 + y2) - (x1 + x2)\n",
    "    # This is known as the Rachford-Rice formulation for the summation constraint\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Evaluating my_f at x=\",x)\n",
    "        print(\"Residuals r=\",r,\"\\n\")\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to define the initial guess as we did with our Newton System in the [previous notebook](../04-publish/05-Newton-Raphson-Methods-for-Systems-of-Equations.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial guess\n",
    "x0 = np.array([0.5, 0.5, 0.55, 0.45, 0.65, 0.35])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run Newton's Method through `scipy.optimize.newton`.  Note that the secant method is used if a derivative is not given to the `scipy.optimize.newton` function, as is the case below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution using scipy:\n",
      " [ 5.00004967e-01  5.36467908e-01  1.09276056e+10  3.55480055e+00\n",
      " -5.38704523e+36  3.50020142e-01]\n"
     ]
    }
   ],
   "source": [
    "xsln1 = optimize.newton(func=my_f, x0=x0)\n",
    "print(\"Solution using scipy:\\n\",xsln1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct answer should be <code> [0.72368421 0.27631579 0.3220339  0.6779661  0.96610169 0.03389831] </code>\n",
    "\n",
    "However, we see that all of the values are incorrect and the third and fifth values diverged.  This illustrates why we prefer to use our own code for Newton's method over scipy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try giving it a second guess of x1 that is close to what we know to be the correct answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution using scipy:\n",
      " [ 5.00004967e-01  5.36467908e-01  1.09276056e+10  3.55480055e+00\n",
      " -5.38704523e+36  3.50020142e-01]\n"
     ]
    }
   ],
   "source": [
    "x1 = np.array([0.72, 0.27, 0.32, 0.67, 0.96, 0.03])\n",
    "xsln2 = optimize.newton(func=my_f, x0=x0, x1=x1)\n",
    "print(\"Solution using scipy:\\n\",xsln2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even adding a second guess closer to the correct root doesn't seem to help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try one more thing.  Now, we're going to call a finite difference function for the derivative so that we aren't defaulting to the secant method with scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution using scipy:\n",
      " [ 1.00000000e+00  2.69555777e-11 -9.45179758e+01  1.25663804e+14\n",
      "  3.49609776e+12  3.52724766e+13]\n"
     ]
    }
   ],
   "source": [
    "dx = 0.001\n",
    "central = lambda x:(my_f(x+dx) - my_f(x-dx))/2/dx\n",
    "xsln3 = optimize.newton(func=my_f, fprime=central, x0=x1)\n",
    "print(\"Solution using scipy:\\n\",xsln3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we see that the solution is incorrect. From this exploration with `scipy.optimize.newton` we can see that it is often better to use the Newton code we developed in the [previous notebook](../04-publish/05-Newton-Raphson-Methods-for-Systems-of-Equations.ipynb)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "L11-Newton-Method-Nonlinear-Equation-Solving.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
