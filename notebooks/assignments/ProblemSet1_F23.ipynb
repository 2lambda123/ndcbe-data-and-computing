{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bq-Qas9VXDaV"
   },
   "source": [
    "# Problem Set 1\n",
    "\n",
    "CBE 60258, University of Notre Dame. © Prof. Alexander Dowling, 2023\n",
    "\n",
    "You may not distribution homework solutions without written permissions from Prof. Alexander Dowling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MXN_O3DcXDaX"
   },
   "outputs": [],
   "source": [
    "# Load required Python libraries.\n",
    "# Please do not remove or rename anything in this cell. The autograder\n",
    "# assumes numpy is loaded as 'np'\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dsphv0S-XDaY"
   },
   "source": [
    "## 1. Air Conditioner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHKa2a-9XDaY"
   },
   "source": [
    "**Learning Objectives**: In this problem, you'll practice solving a mass balance problem with linear algebra (and Python). We'll then explore how a specific modeling mistake causes our solution approach to fail... and why this makes sense based on linear algebra. This is a fun problem. Past (undergraduate) students said this was their \"ah ha!\" moment when they saw the connection between three classes: linear alegbra, introduction to chemical engineering, and numerical and statistical analysis. This is an old exam problem, extended to include Python for the homework.\n",
    "\n",
    "You want to determine the operating conditions of an air conditioning unit. The feed into the air conditioning unit is moist air, and the output is liquid water and somewhat drier air.  It is relatively easy to measure the mole fraction of the air and water in each stream, but measuring the flow rates of the streams is a lot harder.  If we know the composition of the streams, we can compute the flow rates via component and overall mass balances.\n",
    "\n",
    "![ac](https://raw.githubusercontent.com/ndcbe/data-and-computing/main/media/air_conditioner.jpg)\n",
    "\n",
    "Caption: Flowsheet for an air conditioning unit (simplified). Variables $n_1$, ..., $n_5$ are (unknown) molar flows. Mole fractions are given for each stream (DA is dry air, W is water). From Felder and Rousseau (2005)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_xcqMU4XDaY"
   },
   "source": [
    "### 1a. Mathematical Model\n",
    "\n",
    "Propose a system of linearly independent equations that relate $n_1$, $n_2$, $n_3$, $n_4$, and $n_5$. Label your equations, such as \"overall mass balance around entire system\". Finally, write your model in matrix form. Turn in your handwritten work via **Gradescope**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5Leoj4IXDaZ"
   },
   "source": [
    "### 1b. Numerical Solution\n",
    "\n",
    "Solve for $n_1$ through $n_5$ in Python. Store your answer in the numpy array ``n_flow`` in order from $n_1$ to $n_5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5vPAsNFBXDaa",
    "outputId": "5004ac72-2ceb-4dc8-d237-8324c4e49548"
   },
   "outputs": [],
   "source": [
    "# Add your solution here\n",
    "\n",
    "# Print solutions. Note the use of the .format() function, which provides a convenient way\n",
    "# to display messages on screen.\n",
    "print('The molar flows are:')\n",
    "for i in range(len(n_flow)):\n",
    "    print(\"n{0} = {1:0.3f} mol\".format(i+1,n_flow[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qAJTuYOWXDaa"
   },
   "source": [
    "The autograder will check your answer stored in `n_flow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SUleiYPYXDab",
    "nbgrader": {
     "grade": true,
     "grade_id": "1b",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Removed autograder test. You may delete this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2js_ZYfXDab"
   },
   "source": [
    "### 1c. Diagnostics\n",
    "\n",
    "Your classmate attempts to model the system as:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "\t1 & 0 & -1 & 0 & 0 \\\\\n",
    "\t0 & 1 & -1 & -1 & 0 \\\\\n",
    "\t0 & 0.977 & 0 & -0.983 & 0 \\\\\n",
    "\t0 & 0.023 & -1 & -0.017 & 0 \\\\\n",
    "\t0 & 0 & 0 & 1 & -1 \\\\\n",
    "\\end{bmatrix} \\cdot\n",
    "\\begin{bmatrix}\n",
    "\tn_1 \\\\\n",
    "\tn_2 \\\\\n",
    "\tn_3 \\\\\n",
    "\tn_4 \\\\\n",
    "\tn_5\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "\t100 \\\\\n",
    "\t0 \\\\\n",
    "\t0 \\\\\n",
    "\t0 \\\\\n",
    "\t100\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "but their Python code is not working. Your classmate says, \"I am not sure about the mass balances around the air conditioner.\"\n",
    "\n",
    "Answer the questions below. *Hint:* Flow $n_3$ is pure liquid water."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTZdv4e0XDac"
   },
   "source": [
    "**Q1: What is the rank and condition number of the $A$ matrix in your classmate's model?**\n",
    "\n",
    "(You may calculate rank with Python using `numpy.linalg.matrix_rank` and `numpy.linalg.cond`. Please either print out the answers to the screen.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_O8-nyG3XDad",
    "outputId": "3fdfdb33-21bc-4815-fa34-9737e47e3c19"
   },
   "outputs": [],
   "source": [
    "# Please take a minute to verify this matrix matches\n",
    "# the A matrix in your classmate's model.\n",
    "A = np.array([[1, 0, -1, 0, 0],[0, 1, -1, -1, 0],[0, 0.977, 0, -0.983, 0],\n",
    "              [0, 0.023, -1, -0.017, 0],[0, 0, 0, 1, -1]])\n",
    "print(\"A=\\n\",A)\n",
    "\n",
    "# Add your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eNg-FSXXDad"
   },
   "source": [
    "**Q2: What is wrong with the model? How are the rank and condition number helpful in answering this question?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWPvsqJoXDad"
   },
   "source": [
    "**Q3: What mistake did your classmate make?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U00auj7CXDae"
   },
   "source": [
    "**Q4: How can you fix the model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSnPojnsXDan"
   },
   "source": [
    "**Your Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estimating Thermal Gradient with Three Probes\n",
    "\n",
    "We have previously considered the optimal depth of a temperature probe in a metal slab to estimate the thermal gradient. Please take a few minutes to review that material. You will turn in your written work for this problem via **Gradescope**.\n",
    "\n",
    "Your boss now wants to use three probes to reduce the error in estimating the temperature gradient. Let's see if they are right.\n",
    "\n",
    "![ac](https://raw.githubusercontent.com/ndcbe/data-and-computing/main/media/metal-slab-3-probes.jpg)\n",
    "\n",
    "\n",
    "**Assumption 1**: Probe 1 is placed at $x=0$, probe 2 is placed at $x=h$, and probe 3 is placed at $x=2h$.\n",
    "\n",
    "**Assumption 2**: The temperature profile in the slab given by the equation:\n",
    "\n",
    "\\begin{equation} \n",
    "T = T_0 - \\alpha e^{\\beta x}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\alpha$ = 2 °C  and $\\beta$ = 0.5 cm$^{-1}$. The probes have a random error ($ \\sigma_T $) of $\\pm$0.1 °C.\n",
    "\n",
    "**Assumption 3**: The random errors in the temperature measurements are independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Taylor Series for Three Probe System\n",
    "\n",
    "Recall, the temperature measured by the 2 probe system was written out as a Taylor series expansion:\n",
    "\n",
    "\\begin{equation}\n",
    "\\left. T \\right|_{x=1h} = \\left. T \\right|_{x=0} + (1h) \\left. \\frac{\\partial T}{\\partial x} \\right|_{x=0} + \\frac{1}{2!} (1h)^2 \\left. \\frac{\\partial^2 T}{\\partial x^2} \\right|_{x = l}\n",
    "\\end{equation}\n",
    "\n",
    "Using this as a reference, write the Taylor series expansion (up to the first four terms) for $T$ at $x=h$ and $x=2h$.\n",
    "\n",
    "Submit your answer and written work via **Gradescope**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Finite Difference Formula\n",
    "\n",
    "Using your answer from 2a, write the finite difference formula for the three probe system.\n",
    "\n",
    "*Hint*: Eliminate the quadratic term from the Taylor series expansion to give an expression that looks like:\n",
    "\n",
    "\\begin{equation}\n",
    "\\left. \\frac{\\partial{T}}{\\partial{x}} \\right|_{x=0} = \\frac{\\boxed{?} \\ T(0) + \\boxed{?} \\ T(h) + \\boxed{?} \\ T(2h)}{h} + \\boxed{?} \n",
    "\\end{equation}\n",
    "\n",
    "where you determine the expressions to replace $\\boxed{?}$.\n",
    "\n",
    "Submit your answer and written work via **Gradescope**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Algorithm Error\n",
    "\n",
    "Determine the algorithm error for estimating $\\frac{\\partial{T}}{\\partial{x}}$ at $x = 0$.\n",
    "\n",
    "Submit your answer and written work via **Gradescope**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d. Random Error\n",
    "\n",
    "Determine the random error for estimating $\\frac{\\partial{T}}{\\partial{x}}$ at $x = 0$.\n",
    "\n",
    "*Hint*: Use the addition error propagation formula given by:\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma_z^2 = \\left(c_1^2 + c_2^2 + c_3^2\\right)\\sigma_T^2\n",
    "\\end{equation}\n",
    "\n",
    "Submit your answer and written work via **Gradescope**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2e. Optimal Location\n",
    "\n",
    "What is the optimum value of $h$ for which the error in measuring the temperature gradient is minimum? What is the minimum error?\n",
    "\n",
    "Submit your answer and written work via **Gradescope**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Finite Difference Approximations\n",
    "\n",
    "**Main Idea**: Explore the accuracy of the finite difference approximation for $\\nabla f(x)$ and $\\nabla^2 f(x)$ (matricies of first and second derivatives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load libraries\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import sympy as sym\n",
    "# from sympy import symbols, diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "gradescope"
    ]
   },
   "source": [
    "### 3a. Finite difference order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the analysis from class to show the backward and central finite difference truncations errors are $\\mathcal{O}(\\epsilon)$ and $\\mathcal{O}(\\epsilon^2)$, respectively. We discussed these error orders graphically. Please use a Taylor series for your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Problem\n",
    "\n",
    "Consider the function\n",
    "\n",
    "$$ \\begin{align*}\n",
    "f(\\mathbf{x}) &= \\alpha \\mathrm{exp}(-\\beta) \\\\\n",
    "u &= x_1 - 0.8 \\\\\n",
    "v &= x_2 - (a_1 + a_2 u^2 \\sqrt{1 - u} - a_3 u) \\\\\n",
    "\\alpha &= -b_1 + b_2 u^2 \\sqrt{1 - u} + b_3 u \\\\\n",
    "\\beta &= c_1 v^2 (1 - c_2 v) / (1 + c_3 u^2) \\\\\n",
    "{\\mathbf{a}} &= [0.3, 0.6, 0.2]^T \\\\\n",
    "{\\mathbf{b}} &= [5, 26, 3]^T \\\\\n",
    "{\\mathbf{c}} &= [40, 1, 10]^T\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "This is Example 2.19 in Biegler (2010). For our purposes, it is a complicated function we do not want to analytically differentiate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provided Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please review the following code. You do not need to turn anything in for this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finite Difference Code\n",
    "\n",
    "The code below has been adapted from the finite difference examples presented in class. Notice the second input is a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Python function\n",
    "def my_f(x,verbose=False):\n",
    "    ''' Evaluate function given above at point x\n",
    "\n",
    "    Inputs:\n",
    "        x - vector with 2 elements\n",
    "        \n",
    "    Outputs:\n",
    "        f - function value (scalar)\n",
    "    '''\n",
    "    # Constants\n",
    "    a = np.array([0.3, 0.6, 0.2])\n",
    "    b = np.array([5, 26, 3])\n",
    "    c = np.array([40, 1, 10])\n",
    "    \n",
    "    # Intermediates. Recall Python indicies start at 0\n",
    "    u = x[0] - 0.8\n",
    "    s = np.sqrt(1-u)\n",
    "    s2 = np.sqrt(1+u)\n",
    "    v = x[1] -(a[0] + a[1]*u**2*s-a[2]*u)\n",
    "    alpha = -b[0] + b[1]*u**2*s2+ b[2]*u \n",
    "    beta = c[0]*v**2*(1-c[1]*v)/(1+c[2]*u**2)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"##### my_f at x = \",x, \"#####\")\n",
    "        print(\"u = \",u)\n",
    "        print(\"sqrt(1-u) = \",s)\n",
    "        print(\"sqrt(1+u) = \",s2)\n",
    "        print(\"v = \",v)\n",
    "        print(\"alpha = \",alpha)\n",
    "        print(\"beta = \",beta)\n",
    "        print(\"f(x) = \",)\n",
    "        print(\"##### Done. #####\\n\")\n",
    "    \n",
    "    return alpha*np.exp(-beta)\n",
    "\n",
    "## Calculate gradient with central finite difference\n",
    "def my_grad_approx(x,f,eps1,verbose=False):\n",
    "    '''\n",
    "    Calculate gradient of function my_f using central difference formula\n",
    "    \n",
    "    Inputs:\n",
    "        x - point for which to evaluate gradient\n",
    "        f - function to consider\n",
    "        eps1 - perturbation size\n",
    "        \n",
    "    Outputs:\n",
    "        grad - gradient (vector)\n",
    "    '''\n",
    "    \n",
    "    n = len(x)\n",
    "    grad = np.zeros(n)\n",
    "    \n",
    "    if(verbose):\n",
    "        print(\"***** my_grad_approx at x = \",x,\"*****\")\n",
    "    \n",
    "    for i in range(0,n):\n",
    "        \n",
    "        # Create vector of zeros except eps in position i\n",
    "        e = np.zeros(n)\n",
    "        e[i] = eps1\n",
    "        \n",
    "        # Finite difference formula\n",
    "        my_f_plus = f(x + e)\n",
    "        my_f_minus = f(x - e)\n",
    "        \n",
    "        # Diagnostics\n",
    "        if(verbose):\n",
    "            print(\"e[\",i,\"] = \",e)\n",
    "            print(\"f(x + e[\",i,\"]) = \",my_f_plus)\n",
    "            print(\"f(x - e[\",i,\"]) = \",my_f_minus)\n",
    "        \n",
    "        \n",
    "        grad[i] = (my_f_plus - my_f_minus)/(2*eps1)\n",
    "    \n",
    "    if(verbose):\n",
    "        print(\"***** Done. ***** \\n\")\n",
    "    \n",
    "    return grad\n",
    "\n",
    "## Calculate gradient using central finite difference and my_hes_approx\n",
    "def my_hes_approx(x,grad,eps2):\n",
    "    '''\n",
    "    Calculate gradient of function my_f using central difference formula and my_grad\n",
    "    \n",
    "    Inputs:\n",
    "        x - point for which to evaluate gradient\n",
    "        grad - function to calculate the gradient\n",
    "        eps2 - perturbation size (for Hessian NOT gradient approximation)\n",
    "        \n",
    "    Outputs:\n",
    "        H - Hessian (matrix)\n",
    "    '''\n",
    "    \n",
    "    n = len(x)\n",
    "    H = np.zeros([n,n])\n",
    "    \n",
    "    for i in range(0,n):\n",
    "        # Create vector of zeros except eps in position i\n",
    "        e = np.zeros(n)\n",
    "        e[i] = eps2\n",
    "        \n",
    "        # Evaluate gradient twice\n",
    "        grad_plus = grad(x + e)\n",
    "        grad_minus = grad(x - e)\n",
    "        \n",
    "        # Notice we are building the Hessian by column (or row)\n",
    "        H[:,i] = (grad_plus - grad_minus)/(2*eps2)\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test the functions from above\n",
    "\n",
    "## Define test point\n",
    "xt = np.array([0,0])\n",
    "print(\"xt = \",xt,\"\\n\")\n",
    "\n",
    "print(\"f(xt) = \\n\",my_f([0,0]),\"\\n\")\n",
    "\n",
    "## Compute gradient\n",
    "g = my_grad_approx(xt,my_f,1E-6)\n",
    "print(\"grad(xt) = \",g,\"\\n\")\n",
    "\n",
    "## Compute Hessian\n",
    "# Step 1: Create a Lambda (anonymous) function\n",
    "calc_grad = lambda x : my_grad_approx(x,my_f,1E-6)\n",
    "\n",
    "# Step 2: Calculate Hessian approximation\n",
    "H = my_hes_approx(xt,calc_grad,1E-6)\n",
    "print(\"hes(xt) = \\n\",H,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analytic Gradient\n",
    "\n",
    "It turns out that calculating the analytic gradient with Mathematic quickly becomes a mess. Instead, the  following code uses the symbolic computing capabilities in SymPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Encoding the exact gradient with the long expression above is very time-consuming. This is a trick of calculating the \n",
    "symbolic derivative and converting it to an analytic function to be evaluated at a point. \n",
    "'''\n",
    "\n",
    "# Define function to use with symbolic computing framework\n",
    "def f(x1,x2):\n",
    "    a = np.array([0.3, 0.6, 0.2])\n",
    "    b = np.array([5, 26, 3])\n",
    "    b1 = 5;\n",
    "    c = np.array([40, 1, 10])\n",
    "    u = x1 - 0.8\n",
    "    v = x2 -(a[0] + a[1]*u**2*(1-u)**0.5-a[2]*u)\n",
    "    alpha = b[1]*u**2*(1+u)**0.5 + b[2]*u -b[0]\n",
    "    beta = c[0]*v**2*(1-c[1]*v)/(1+c[2]*u**2)\n",
    "    return alpha*sym.exp(-1*beta)\n",
    "\n",
    "# Define function to use later\n",
    "def my_grad_exact(x):\n",
    "    x1, x2 = sym.symbols('x1 x2')\n",
    "    DerivativeOfF1 = sym.lambdify((x1,x2),sym.diff(f(x1,x2),x1));\n",
    "    DerivativeOfF2 = sym.lambdify((x1,x2),sym.diff(f(x1,x2),x2));\n",
    "    #DerivativeOfF2 = sym.lambdify((x1,x2),gradf2(x1,x2));\n",
    "    #F = sym.lambdify((x1,x2),f(x1,x2));\n",
    "    return np.array([DerivativeOfF1(x[0],x[1]),DerivativeOfF2(x[0],x[1])])\n",
    "    \n",
    "x = np.array([0,0])\n",
    "print(\"The exact gradient is \\n\",my_grad_exact(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analytic Hessian\n",
    "\n",
    "The code below assembles the analytic Hessian using the symbolic computing framework in NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x1,x2):\n",
    "    \n",
    "    a = np.array([0.3, 0.6, 0.2])\n",
    "    b = np.array([5, 26, 3])\n",
    "    b1 = 5;\n",
    "    c = np.array([40, 1, 10])\n",
    "    u = x1 - 0.8\n",
    "    v = x2 -(a[0] + a[1]*u**2*(1-u)**0.5-a[2]*u)\n",
    "    alpha = b[1]*u**2*(1+u)**0.5 + b[2]*u -b[0]\n",
    "    beta = c[0]*v**2*(1-c[1]*v)/(1+c[2]*u**2)\n",
    "    return alpha*sym.exp(-1*beta)\n",
    "\n",
    "\n",
    "def my_hes_exact(x):\n",
    "    x1, x2 = sym.symbols('x1 x2')\n",
    "    HessianOfF11 = sym.lambdify((x1,x2),sym.diff(f(x1,x2),x1,x1));\n",
    "    HessianOfF12 = sym.lambdify((x1,x2),sym.diff(f(x1,x2),x1,x2));\n",
    "    HessianOfF21 = sym.lambdify((x1,x2),sym.diff(f(x1,x2),x2,x1));\n",
    "    HessianOfF22 = sym.lambdify((x1,x2),sym.diff(f(x1,x2),x2,x2));\n",
    "    #DerivativeOfF2 = sym.lambdify((x1,x2),gradf2(x1,x2));\n",
    "    #F = sym.lambdify((x1,x2),f(x1,x2));\n",
    "    return np.array([[HessianOfF11(x[0],x[1]),HessianOfF12(x[0],x[1])],[HessianOfF21(x[0],x[1]),HessianOfF22(x[0],x[1])]])\n",
    "    \n",
    "x = np.array([0,0])\n",
    "print(\"The exact Hessian is \\n\",my_hes_exact(x))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Finite Difference Comparison\n",
    "\n",
    "Repeat the analysis procedure from the finite difference class notebook to find the value of $\\epsilon_1$ that gives the smallest approximation error. Some tips:\n",
    "1. Write a `for` loop to iterate over many values of $\\epsilon_1$\n",
    "2. Use $|| \\nabla f(x;\\epsilon_1)_{approx} - \\nabla f(x)_{exact} ||$ to measure the error. Your choice on which norm(s) to use. Please label your plot with the norm(s) you used.\n",
    "3. Make a log-log plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hessian Finite Difference using Approximate Gradient\n",
    "\n",
    "Repeat the analysis from above. Use `my_grad_approx` and the best value for $\\epsilon_1$ you previously found. What value of $\\epsilon_2$ gives the lowest Hessian approximation error? Note: $\\epsilon_1$ is used in the gradient approximation and $\\epsilon_2$ is used in the Hessian approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hessian Finite Difference using Exact Gradient\n",
    "\n",
    "Repeat the analysis from above using `my_grad_exact`. What value of $\\epsilon_2$ gives the lower Hessian approximation error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Final Answers\n",
    "\n",
    "**Record your final answers below**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Using $\\epsilon_1 = $ ... gives error $|| \\nabla f(x;\\epsilon_1)_{approx} - \\nabla f(x)_{exact} || = $ ...\n",
    "\n",
    "B. Using $\\epsilon_1 = $ ... and $\\epsilon_2 = $ ... gives error $|| \\nabla^2 f(x;\\epsilon_1,\\epsilon_2)_{approx} - \\nabla^2 f(x)_{exact} || = $ ...\n",
    "\n",
    "C. Using $\\epsilon_2 = $ gives error $|| \\nabla^2 f(x;\\epsilon_2)_{approx} - \\nabla^2 f(x)_{exact} || = $ ...\n",
    "\n",
    "These answers were computed using the (fill in blank) norm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the benefit of using the *exact gradient* when approximating the Hessian with central finite difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multivariable Taylor Series\n",
    "\n",
    "You will use `my_grad_exact`, `my_grad_approx`, `my_hes_exact`, and `my_hes_approx` to construct Taylor series approximations to an arbitrary twice differentiable continuous functions with inputs $x \\in \\mathbb{R}^2$. We will then consider visualize the Taylor series approximation in 3D.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Create a function to plot the first order Taylor series using $\\nabla f$\n",
    "\n",
    "Create a general function that:\n",
    "1. Constructs a Taylor series using $\\nabla f$ centered around a given point\n",
    "2. Plots the true function and Taylor series approximation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taylor1(xc, f, grad, dx):\n",
    "    '''\n",
    "    Constructs a Taylor series using first derivates and visualizes in 3D\n",
    "    \n",
    "    Arguments:\n",
    "        xc - point to center Taylor series\n",
    "        f - function that computes function value. Only has one input (x)\n",
    "        grad - function that computes gradient. Only has one input (x)\n",
    "        dx - list or numpy array. creates 3D plot over xc[0] +/- dx[0], xc[1] +/- dx[1]\n",
    "    \n",
    "    Returns:\n",
    "        none\n",
    "        \n",
    "    Actions:\n",
    "        3D plot\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Add your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First order Taylor Series using `my_grad_approx`\n",
    "\n",
    "Consider $x_c = [0.7, 0.3]^T$ (center of Taylor series) and $\\Delta x = [0.5, 0.5]^T$ (domain for plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify epsilon1\n",
    "calc_grad = lambda x : my_grad_approx(x,my_f,1E-6)\n",
    "\n",
    "# Specify dx\n",
    "dx = [0.5, 0.5]\n",
    "\n",
    "# Specify xc\n",
    "xc = np.array([0.7, 0.3])\n",
    "\n",
    "taylor1(xc, my_f, calc_grad, dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First order Taylor Series using `my_grad_exact`\n",
    "\n",
    "Consider $x_c = [0.7, 0.3]^T$ (center of Taylor series) and $\\Delta x = [0.5, 0.5]^T$ (domain for plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify epsilon1\n",
    "calc_grad = lambda x : my_grad_exact(x)\n",
    "\n",
    "# Specify dx\n",
    "dx = [0.5, 0.5]\n",
    "\n",
    "# Specify xc\n",
    "xc = np.array([0.7, 0.3])\n",
    "\n",
    "taylor1(xc, my_f, calc_grad, dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function to plot the second order Taylor series using $\\nabla f$ and $\\nabla^2 f$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taylor2(xc, f, grad, hes, dx):\n",
    "    '''\n",
    "    Constructs a Taylor series using first derivates and visualizes in 3D\n",
    "    \n",
    "    Inputs:\n",
    "        xc - point to center Taylor series\n",
    "        f - computes function value. Only has one input (x)\n",
    "        grad - computes gradient. Only has one input (x)\n",
    "        hes - computes the Hessian. Only has one input (x)\n",
    "        dx - creates 3D plot over xc[0] +/- dx[0], xc[1] +/- dx[1]\n",
    "    \n",
    "    Outputs:\n",
    "        none\n",
    "        \n",
    "    Creates:\n",
    "        3D plot\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    ### Evaluates function and gradiant\n",
    "    fval = f(xc)\n",
    "    gval = grad(xc)\n",
    "    Hval = hes(xc)\n",
    "    \n",
    "    ### Creates domain for plotting\n",
    "    x1 = np.arange(xc[0] - dx[0],xc[0] + dx[0],dx[0]/100)\n",
    "    x2 = np.arange(xc[1] - dx[1],xc[1] + dx[1],dx[1]/100)\n",
    "    \n",
    "    ## Create a matrix of all points to sample\n",
    "    X1, X2 = np.meshgrid(x1, x2)\n",
    "    n1 = len(x1)\n",
    "    n2 = len(x2)\n",
    "\n",
    "    ## Allocate matrix for true function value\n",
    "    F = np.zeros([n2, n1])\n",
    "\n",
    "    ## Allocate matrix for Taylor series approximation\n",
    "    T = np.zeros([n2, n1])    \n",
    "    \n",
    "    xtemp = np.zeros(2)\n",
    "\n",
    "    # Evaluate f(x) and Taylor series over grid\n",
    "    for i in range(0,n1):\n",
    "        xtemp[0] = x1[i]\n",
    "        for j in range(0,n2):\n",
    "            xtemp[1] = x2[j]\n",
    "            \n",
    "            # Evaluate f(x)\n",
    "            F[j,i] = my_f(xtemp)\n",
    "\n",
    "            # Evaluate Taylor series\n",
    "            dx_ = xtemp - xc\n",
    "            \n",
    "            '''\n",
    "            print(\"dx = \",dx)\n",
    "            print(\"gval = \",gval)\n",
    "            print(\"Hval = \",Hval)\n",
    "            '''\n",
    "            \n",
    "            temp = Hval.dot(dx_)\n",
    "            # print(\"Hval * dx = \",temp)\n",
    "            \n",
    "            \n",
    "            # T[j,i] = fval + gval.dot(dx_) + 0.5*(temp).dot(dx_)\n",
    "            T[j,i] = fval + gval.dot(dx_) + 0.5*(dx_.dot(Hval.dot(dx_)))\n",
    "            \n",
    "    # Create 3D figure\n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "\n",
    "    # Plot f(x)\n",
    "    surf = ax.plot_surface(X1, X2, F, linewidth=0,cmap=cm.coolwarm,antialiased=True,label=\"f(x)\")\n",
    "\n",
    "    # Plot Taylor series approximation\n",
    "    surf = ax.plot_surface(X1, X2, T, linewidth=0,cmap=cm.PiYG,antialiased=True,label=\"Taylor series\")\n",
    "    \n",
    "    # Add candidate point\n",
    "    ax.scatter(xc[0],xc[1],fval,s=50,color=\"black\",depthshade=True)\n",
    "\n",
    "    # Draw vertical line through stationary point to help visualization\n",
    "    # Maximum value in array\n",
    "    fmax = np.amax(F)\n",
    "    fmin = np.amin(F)\n",
    "    ax.plot([xc[0], xc[0]], [xc[1], xc[1]], [fmin,fmax],color=\"black\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second order Taylor series using `my_grad_approx` and `my_hes_approx`\n",
    "\n",
    "Consider $x_c = [0.7, 0.3]^T$ (center of Taylor series) and $\\Delta x = [0.2, 0.2]^T$ (domain for plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify epsilon1\n",
    "calc_grad = lambda x : my_grad_approx(x,my_f,1E-6)\n",
    "\n",
    "# Specify epsilon2\n",
    "calc_hes = lambda x : my_hes_approx(x, calc_grad, 1E-6)\n",
    "\n",
    "# Specify dx\n",
    "dx = [0.2, 0.2]\n",
    "\n",
    "# Specify xc\n",
    "xc = np.array([0.7, 0.3])\n",
    "\n",
    "taylor2(xc, my_f, calc_grad, calc_hes, dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second order Taylor series using `my_grad_exact` and `my_hes_exact`\n",
    "\n",
    "Consider $x_c = [0.7, 0.3]^T$ (center of Taylor series) and $\\Delta x = [0.2, 0.2]^T$ (domain for plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([0,0])\n",
    "# Specify epsilon1\n",
    "calc_grad = lambda x : my_grad_exact(x)\n",
    "\n",
    "# Specify epsilon2\n",
    "calc_hes = lambda x1 : my_hes_exact(x1)\n",
    "\n",
    "# Specify dx\n",
    "dx = [0.2, 0.2]\n",
    "\n",
    "# Specify xc\n",
    "xc = np.array([0.7, 0.3])\n",
    "\n",
    "taylor2(xc, my_f, calc_grad, calc_hes, dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write 1 or 2 sentences to describe the the shapes for the first order and second order Taylor series approximations? Why do these shapes make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a visible difference in the Taylor series approximations using the finite difference versus exact derivatives? Why does this make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
