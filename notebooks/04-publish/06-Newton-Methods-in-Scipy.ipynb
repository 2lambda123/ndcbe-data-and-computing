{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vwvvdc673Awp"
   },
   "source": [
    "# Newton Methods in Scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "After studying this notebook, completing the activities, and asking questions in class, you should be able to:\n",
    "* Use numpy to solve the flash example problem from the [last notebook](../04-publish/05-Newton-Raphson-Methods-for-Systems-of-Equations.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import numpy as np\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8HrL39kh_LnS",
    "tags": []
   },
   "source": [
    "## Using ``scipy`` instead\n",
    "\n",
    "`numpy` and `scipy` offer a few different implementations of Newton's method. However, we found these to be unreliable in the past. Instead, we recommend either using the Newton solver we put together in the [last notebook](../04-publish/05-Newton-Raphson-Methods-for-Systems-of-Equations.ipynb) or Pyomo (future notebook).\n",
    "\n",
    "However, we will show how this is done using `scipy.optimize.newton` in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip\"> \n",
    "<p class=\"title\"><b>Note</b></p>\n",
    " Note the difference between `scipy.optimize.newton` and `scipy.optimize.fsolve`.  The first is used to solve scalar-valued functions (functions that return a single value, i.e. the polynomial example below).  The second is used to solve vector-valued functions (functions that return a vector of *multiple* values, i.e. the flash example below).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function newton in module scipy.optimize._zeros_py:\n",
      "\n",
      "newton(func, x0, fprime=None, args=(), tol=1.48e-08, maxiter=50, fprime2=None, x1=None, rtol=0.0, full_output=False, disp=True)\n",
      "    Find a zero of a real or complex function using the Newton-Raphson\n",
      "    (or secant or Halley's) method.\n",
      "    \n",
      "    Find a zero of the scalar-valued function `func` given a nearby scalar\n",
      "    starting point `x0`.\n",
      "    The Newton-Raphson method is used if the derivative `fprime` of `func`\n",
      "    is provided, otherwise the secant method is used. If the second order\n",
      "    derivative `fprime2` of `func` is also provided, then Halley's method is\n",
      "    used.\n",
      "    \n",
      "    If `x0` is a sequence with more than one item, `newton` returns an array:\n",
      "    the zeros of the function from each (scalar) starting point in `x0`.\n",
      "    In this case, `func` must be vectorized to return a sequence or array of\n",
      "    the same shape as its first argument. If `fprime` (`fprime2`) is given,\n",
      "    then its return must also have the same shape: each element is the first\n",
      "    (second) derivative of `func` with respect to its only variable evaluated\n",
      "    at each element of its first argument.\n",
      "    \n",
      "    `newton` is for finding roots of a scalar-valued functions of a single\n",
      "    variable. For problems involving several variables, see `root`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    func : callable\n",
      "        The function whose zero is wanted. It must be a function of a\n",
      "        single variable of the form ``f(x,a,b,c...)``, where ``a,b,c...``\n",
      "        are extra arguments that can be passed in the `args` parameter.\n",
      "    x0 : float, sequence, or ndarray\n",
      "        An initial estimate of the zero that should be somewhere near the\n",
      "        actual zero. If not scalar, then `func` must be vectorized and return\n",
      "        a sequence or array of the same shape as its first argument.\n",
      "    fprime : callable, optional\n",
      "        The derivative of the function when available and convenient. If it\n",
      "        is None (default), then the secant method is used.\n",
      "    args : tuple, optional\n",
      "        Extra arguments to be used in the function call.\n",
      "    tol : float, optional\n",
      "        The allowable error of the zero value. If `func` is complex-valued,\n",
      "        a larger `tol` is recommended as both the real and imaginary parts\n",
      "        of `x` contribute to ``|x - x0|``.\n",
      "    maxiter : int, optional\n",
      "        Maximum number of iterations.\n",
      "    fprime2 : callable, optional\n",
      "        The second order derivative of the function when available and\n",
      "        convenient. If it is None (default), then the normal Newton-Raphson\n",
      "        or the secant method is used. If it is not None, then Halley's method\n",
      "        is used.\n",
      "    x1 : float, optional\n",
      "        Another estimate of the zero that should be somewhere near the\n",
      "        actual zero. Used if `fprime` is not provided.\n",
      "    rtol : float, optional\n",
      "        Tolerance (relative) for termination.\n",
      "    full_output : bool, optional\n",
      "        If `full_output` is False (default), the root is returned.\n",
      "        If True and `x0` is scalar, the return value is ``(x, r)``, where ``x``\n",
      "        is the root and ``r`` is a `RootResults` object.\n",
      "        If True and `x0` is non-scalar, the return value is ``(x, converged,\n",
      "        zero_der)`` (see Returns section for details).\n",
      "    disp : bool, optional\n",
      "        If True, raise a RuntimeError if the algorithm didn't converge, with\n",
      "        the error message containing the number of iterations and current\n",
      "        function value. Otherwise, the convergence status is recorded in a\n",
      "        `RootResults` return object.\n",
      "        Ignored if `x0` is not scalar.\n",
      "        *Note: this has little to do with displaying, however,\n",
      "        the `disp` keyword cannot be renamed for backwards compatibility.*\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    root : float, sequence, or ndarray\n",
      "        Estimated location where function is zero.\n",
      "    r : `RootResults`, optional\n",
      "        Present if ``full_output=True`` and `x0` is scalar.\n",
      "        Object containing information about the convergence. In particular,\n",
      "        ``r.converged`` is True if the routine converged.\n",
      "    converged : ndarray of bool, optional\n",
      "        Present if ``full_output=True`` and `x0` is non-scalar.\n",
      "        For vector functions, indicates which elements converged successfully.\n",
      "    zero_der : ndarray of bool, optional\n",
      "        Present if ``full_output=True`` and `x0` is non-scalar.\n",
      "        For vector functions, indicates which elements had a zero derivative.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    root_scalar : interface to root solvers for scalar functions\n",
      "    root : interface to root solvers for multi-input, multi-output functions\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    The convergence rate of the Newton-Raphson method is quadratic,\n",
      "    the Halley method is cubic, and the secant method is\n",
      "    sub-quadratic. This means that if the function is well-behaved\n",
      "    the actual error in the estimated zero after the nth iteration\n",
      "    is approximately the square (cube for Halley) of the error\n",
      "    after the (n-1)th step. However, the stopping criterion used\n",
      "    here is the step size and there is no guarantee that a zero\n",
      "    has been found. Consequently, the result should be verified.\n",
      "    Safer algorithms are brentq, brenth, ridder, and bisect,\n",
      "    but they all require that the root first be bracketed in an\n",
      "    interval where the function changes sign. The brentq algorithm\n",
      "    is recommended for general use in one dimensional problems\n",
      "    when such an interval has been found.\n",
      "    \n",
      "    When `newton` is used with arrays, it is best suited for the following\n",
      "    types of problems:\n",
      "    \n",
      "    * The initial guesses, `x0`, are all relatively the same distance from\n",
      "      the roots.\n",
      "    * Some or all of the extra arguments, `args`, are also arrays so that a\n",
      "      class of similar problems can be solved together.\n",
      "    * The size of the initial guesses, `x0`, is larger than O(100) elements.\n",
      "      Otherwise, a naive loop may perform as well or better than a vector.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from scipy import optimize\n",
      "    >>> import matplotlib.pyplot as plt\n",
      "    \n",
      "    >>> def f(x):\n",
      "    ...     return (x**3 - 1)  # only one real root at x = 1\n",
      "    \n",
      "    ``fprime`` is not provided, use the secant method:\n",
      "    \n",
      "    >>> root = optimize.newton(f, 1.5)\n",
      "    >>> root\n",
      "    1.0000000000000016\n",
      "    >>> root = optimize.newton(f, 1.5, fprime2=lambda x: 6 * x)\n",
      "    >>> root\n",
      "    1.0000000000000016\n",
      "    \n",
      "    Only ``fprime`` is provided, use the Newton-Raphson method:\n",
      "    \n",
      "    >>> root = optimize.newton(f, 1.5, fprime=lambda x: 3 * x**2)\n",
      "    >>> root\n",
      "    1.0\n",
      "    \n",
      "    Both ``fprime2`` and ``fprime`` are provided, use Halley's method:\n",
      "    \n",
      "    >>> root = optimize.newton(f, 1.5, fprime=lambda x: 3 * x**2,\n",
      "    ...                        fprime2=lambda x: 6 * x)\n",
      "    >>> root\n",
      "    1.0\n",
      "    \n",
      "    When we want to find zeros for a set of related starting values and/or\n",
      "    function parameters, we can provide both of those as an array of inputs:\n",
      "    \n",
      "    >>> f = lambda x, a: x**3 - a\n",
      "    >>> fder = lambda x, a: 3 * x**2\n",
      "    >>> rng = np.random.default_rng()\n",
      "    >>> x = rng.standard_normal(100)\n",
      "    >>> a = np.arange(-50, 50)\n",
      "    >>> vec_res = optimize.newton(f, x, fprime=fder, args=(a, ), maxiter=200)\n",
      "    \n",
      "    The above is the equivalent of solving for each value in ``(x, a)``\n",
      "    separately in a for-loop, just faster:\n",
      "    \n",
      "    >>> loop_res = [optimize.newton(f, x0, fprime=fder, args=(a0,),\n",
      "    ...                             maxiter=200)\n",
      "    ...             for x0, a0 in zip(x, a)]\n",
      "    >>> np.allclose(vec_res, loop_res)\n",
      "    True\n",
      "    \n",
      "    Plot the results found for all values of ``a``:\n",
      "    \n",
      "    >>> analytical_result = np.sign(a) * np.abs(a)**(1/3)\n",
      "    >>> fig, ax = plt.subplots()\n",
      "    >>> ax.plot(a, analytical_result, 'o')\n",
      "    >>> ax.plot(a, vec_res, '.')\n",
      "    >>> ax.set_xlabel('$a$')\n",
      "    >>> ax.set_ylabel('$x$ where $f(x, a)=0$')\n",
      "    >>> plt.show()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# documentation for Newton's method in scipy\n",
    "help(optimize.newton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Polynomial Example Revisited Using Scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ c(x) = 3 x^3 + 2 x^2 - 5 x - 20 $$\n",
    "\n",
    "![Newton Polynomial](https://ndcbe.github.io/data-and-computing/_images/newton_polynomial.png)\n",
    "    \n",
    "In the following cells we will demonstrate the use of Scipy to perform the Newton-Raphson method for the polynomial example from [this previous notebook](../04-publish/02-Newton-Raphson-Method-in-One-Dimension.ipynb).\n",
    "\n",
    "First, we need to run the code we already developed for the polynomial function and its derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonlinear_function(x):\n",
    "    ''' compute a nonlinear function for demonstration\n",
    "    Arguments:\n",
    "        x: scalar\n",
    "    Returns:\n",
    "        c(x): scalar\n",
    "    '''\n",
    "    return 3*x**3 + 2*x**2 - 5*x-20\n",
    "\n",
    "def Dnonlinear_function(x):\n",
    "    ''' compute 1st derivative of nonlinear function for demonstration\n",
    "    Arguments:\n",
    "        x: scalar\n",
    "    Returns:\n",
    "        c'(x): scalar\n",
    "    '''\n",
    "    return 9*x**2 + 4*x - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to provide an initial guess as we did before we the code we deveoped for Newton's Method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run Newton's Method through `scipy.optimize.newton`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The root is found at 1.9473052357731322\n"
     ]
    }
   ],
   "source": [
    "polysln = optimize.newton(func=nonlinear_function, x0 = guess, fprime=Dnonlinear_function)\n",
    "print(\"The root is found at\",polysln)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7nE5fTM23Ax_"
   },
   "source": [
    "## Flash Problem Revisted Using Scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yNNP7IN_3Ax_"
   },
   "source": [
    "Recall the flash problem from [this previous notebook](../04-publish/01-Modeling-Systems-of-Nonlinear-Equations.ipynb) that we solved in the [last notebook](../04-publish/05-Newton-Raphson-Methods-for-Systems-of-Equations.ipynb) using Newton's Method.  In the following cells we will demonstrate the use of Scipy to perform the Newton-Raphson method.\n",
    "\n",
    "![flash](https://ndcbe.github.io/data-and-computing/_images/flash-system.png)\n",
    "\n",
    "**Parameters (given)**:\n",
    "* $F$ feed inlet flowrate, mol/time or kg/time\n",
    "* $z_1$ composition of species 1 in feed, mol% or mass%\n",
    "* $z_2$ composition of species 2 in feed, mol% or mass%\n",
    "* $K_1$ partion coefficient for species 1, mol%/mol% or mass% / mass%\n",
    "* $K_2$ partion coefficient for species 2, mol%/mol% or mass% / mass%\n",
    "\n",
    "**Variables (unknown)**:\n",
    "* $L$ liquid outlet flowrate, mol/time or kg/time\n",
    "* $x_1$ composition of species 1 in liquid, mol% or mass%\n",
    "* $x_2$ composition of species 2 in liquid, mol% or mass%\n",
    "* $V$ vapor outlet flowrate, mol/time or kg/time\n",
    "* $y_1$ composition of species 1 in vapor, mol% or mass%\n",
    "* $y_2$ composition of species 2 in vapor, mol% or mass%\n",
    "\n",
    "How to solve the flash problem and other multidimensional problem with $n$ unknown variables and $n$ nonlinear equations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ejJp4YwW3AyF"
   },
   "source": [
    "### System of Equations in Canonical Form\n",
    "\n",
    "$$\\mathbf{F}(\\mathbf{x}) = \\begin{pmatrix}\n",
    "L + V - F\\\\\n",
    "Vy_1 + L x_1 - F z_1 \\\\\n",
    "V y_2 + L x_2 - F z_2 \\\\\n",
    "y_1 - K_1 x_1 \\\\\n",
    "y_2 - K_2 x_2 \\\\\n",
    "y_1 + y_2 - x_1 - x_2\n",
    "\\end{pmatrix},$$\n",
    "\n",
    "with $\\mathbf{x} = (L, V, x_1, x_2, y_1, y_2).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First run the code below to define the system of nonlinear equations given in the [previous notebook](../04-publish/05-Newton-Raphson-Methods-for-Systems-of-Equations.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Fv_aYYF3AyG",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nonlinear canonical system of equations\n",
    "def my_f(x,verbose=False):\n",
    "    ''' Nonlinear system of equations in conancial form F(x) = 0\n",
    "    Copied from previous notebook.\n",
    "    \n",
    "    Arg:\n",
    "        x: vector of variables\n",
    "        \n",
    "    Returns:\n",
    "        r: residual, F(x)\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Initialize residuals\n",
    "    r = np.zeros(6)\n",
    "    \n",
    "    # given data\n",
    "    F = 1.0\n",
    "    z1 = 0.5\n",
    "    z2 = 0.5\n",
    "    K1 = 3\n",
    "    K2 = 0.05\n",
    "    \n",
    "    # copy values from x to more meaningful names\n",
    "    L = x[0]\n",
    "    V = x[1]\n",
    "    x1 = x[2]\n",
    "    x2 = x[3]\n",
    "    y1 = x[4]\n",
    "    y2 = x[5]\n",
    "    \n",
    "    # equation 1: overall mass balance\n",
    "    r[0] = V + L - F\n",
    "    \n",
    "    # equations 2 and 3: component mass balances\n",
    "    r[1] = V*y1 + L*x1 - F*z1\n",
    "    r[2] = V*y2 + L*x2 - F*z2\n",
    "    \n",
    "    # equation 4 and 5: equilibrium\n",
    "    r[3] = y1 - K1*x1\n",
    "    r[4] = y2 - K2*x2\n",
    "    \n",
    "    # equation 6: summation\n",
    "    r[5] = (y1 + y2) - (x1 + x2)\n",
    "    # This is known as the Rachford-Rice formulation for the summation constraint\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Evaluating my_f at x=\",x)\n",
    "        print(\"Residuals r=\",r,\"\\n\")\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try `optimize.newton`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially you might be inclined to use `optimize.newton` as with the polynomial example.  Let's see what happens when we use that below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial guess from the [previous notebook](../04-publish/05-Newton-Raphson-Methods-for-Systems-of-Equations.ipynb).\n",
    "x0 = np.array([0.5, 0.5, 0.55, 0.45, 0.65, 0.35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution using scipy:\n",
      " [ 5.00004967e-01  5.36467908e-01  1.09276056e+10  3.55480055e+00\n",
      " -5.38704523e+36  3.50020142e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ebrea\\anaconda3\\envs\\jbook\\lib\\site-packages\\scipy\\optimize\\_zeros_py.py:466: RuntimeWarning: some failed to converge after 50 iterations\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# incorrect scipy function to solve flash example\n",
    "xsln1 = optimize.newton(func=my_f, x0=x0)\n",
    "print(\"Solution using scipy:\\n\",xsln1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct answer should be <code> [0.72368421 0.27631579 0.3220339  0.6779661  0.96610169 0.03389831] </code>\n",
    "\n",
    "However, we see that all of the values are incorrect and the third and fifth values diverged.\n",
    "\n",
    "Consulting the [scipy documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.newton.html) revelas that `optimize.newton` is only for scalar-valued functions. *Notice that `optimize.newton` did not give a warning about our function being vector-valued; it will not alert you if you use it incorrectly.* Instead, it just did not converge.\n",
    "\n",
    "This illustrates why we choose not to use `scipy.optimize.newton` for a system of equations. Also, if something does not work as expected, check the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instead use `optimize.fsolve` for multivariate systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we will use `optimize.fsolve` since this is a vector-valued function (returns a vector of multiple values).  We can't use `optimize.newton` because it only works for scalar-valued functions (return a single value) like the above polynomial example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72368421 0.27631579 0.3220339  0.6779661  0.96610169 0.03389831]\n"
     ]
    }
   ],
   "source": [
    "# correct scipy function to solve flash example\n",
    "xsln = optimize.fsolve(my_f,x0)\n",
    "print(xsln)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformed System of Equations in Canonical Form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "One last idea. We can transform the system of equations by introducing the following new log transformed variables for composition:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\bar{x_1} = \\log_{10}(x_1), \\quad \\bar{x_2} = \\log_{10}(x_2), \\quad \\bar{y_1} = \\log_{10}(y_2), \\quad \\bar{y_2} = \\log_{10}(y_2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's reexamine the equilibrium equations:\n",
    "\n",
    "$$y_1 = K_1 x_1, \\qquad y_2 = K_2 x_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the log of both sides of the equations gives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\log_{10}(y_1) = \\log_{10}(K_1 x_1), \\qquad \\log_{10}(y_2) = \\log_{10}(K_2 x_2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then apply properties of logortihms:\n",
    "$$\\log_{10}(y_1) = \\log_{10}(K_1) +  \\log_{10}(x_1), \\qquad \\log_{10}(y_2) = \\log_{10}(K_2) + \\log_{10}(x_2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally substitute the new variables to obtain a new systems of equations:\n",
    "\n",
    "$$\\mathbf{\\bar{F}}(\\mathbf{\\bar{x}}) = \\begin{pmatrix}\n",
    "L + V - F\\\\\n",
    "V \\cdot 10^{\\bar{y}_1} + L \\cdot 10^{\\bar{x}_1} - F \\cdot z_1 \\\\\n",
    "V \\cdot 10^{\\bar{y}_2} + L \\cdot 10^{\\bar{x}_2} - F \\cdot z_2 \\\\\n",
    "\\bar{y}_1 - \\log_{10}(K_1) - \\bar{x}_1 \\\\\n",
    "\\bar{y}_1 - \\log_{10}(K_1) - \\bar{x}_1 \\\\\n",
    "10^{\\bar{y}_1} + 10^{\\bar{y}_2} - 10^{\\bar{x}_1} - 10^{\\bar{x}_2}\n",
    "\\end{pmatrix},$$\n",
    "\n",
    "with $\\mathbf{\\bar{x}} = (L, V, \\bar{x}_1, \\bar{x}_2, \\bar{y}_1, \\bar{y}_2).$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nonlinear canonical system of equations\n",
    "def my_f_transformed(x_bar,verbose=False):\n",
    "    ''' Nonlinear system of equations in conancial form F(x) = 0\n",
    "    Copied from previous notebook.\n",
    "    \n",
    "    Arg:\n",
    "        x_bar: vector of (partially transformed) variables\n",
    "        \n",
    "    Returns:\n",
    "        r: residual, F(x)\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # Initialize residuals\n",
    "    r = np.zeros(6)\n",
    "    \n",
    "    # given data\n",
    "    F = 1.0\n",
    "    z1 = 0.5\n",
    "    z2 = 0.5\n",
    "    K1 = 3\n",
    "    K2 = 0.05\n",
    "    \n",
    "    # copy values from x to more meaningful names\n",
    "    L = x_bar[0]\n",
    "    V = x_bar[1]\n",
    "    log_x1 = x_bar[2]\n",
    "    log_x2 = x_bar[3]\n",
    "    log_y1 = x_bar[4]\n",
    "    log_y2 = x_bar[5]\n",
    "    \n",
    "    # undo transformation (for convience so we do not need to significantly modify the equations below)\n",
    "    x1 = 10**log_x1\n",
    "    x2 = 10**log_x2\n",
    "    y1 = 10**log_y1\n",
    "    y2 = 10**log_y2\n",
    "    \n",
    "    # equation 1: overall mass balance\n",
    "    r[0] = V + L - F\n",
    "    \n",
    "    # equations 2 and 3: component mass balances\n",
    "    r[1] = V*y1 + L*x1 - F*z1\n",
    "    r[2] = V*y2 + L*x2 - F*z2\n",
    "    \n",
    "    # equation 4 and 5: equilibrium\n",
    "    r[3] = log_y1 - np.log10(K1) - log_x1\n",
    "    r[4] = log_y2 - np.log10(K2) - log_x2\n",
    "    \n",
    "    # equation 6: summation\n",
    "    r[5] = (y1 + y2) - (x1 + x2)\n",
    "    # This is known as the Rachford-Rice formulation for the summation constraint\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Evaluating my_f_bar at x_bar=\",x_bar)\n",
    "        print(\"Residuals r=\",r,\"\\n\")\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also define a functon to undo the transformation and print the solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's transform the initial guesses from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_bar = np.array([0.5, 0.5, np.log10(0.55), np.log10(0.45), np.log10(0.65), np.log10(0.35)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can try and use `optimize.fsovle` again with our transformed system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.72368421  0.27631579 -0.49209841 -0.16879202 -0.01497716 -1.46982202]\n"
     ]
    }
   ],
   "source": [
    "sln = optimize.fsolve(my_f_transformed,x0_bar)\n",
    "print(sln)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that some of the answers are correct, while others are not.  From these attempts to find the solution, we have found that it's best to use the code we develop for Newton's method or the `scipy.optimize.fsolve` function."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "L11-Newton-Method-Nonlinear-Equation-Solving.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
